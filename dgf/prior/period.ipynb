{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating $p(T)$ from APLAWD\n",
    "\n",
    "- APLAWD database [@Lindsey1987]. British English.\n",
    "\n",
    "- APLAWD GCI markings [@Serwy2017]. Very high-quality, hand-corrected.\n",
    "\n",
    "- Time shift of WAV vs. EGG is ~ 0.95 msec [@Naylor2007]. **OK: Implemented.**\n",
    "\n",
    "## Note about jitter\n",
    "\n",
    "We model the 'true' pitch periods by a GP with $\\sigma^2_n$ (i.e., `noise_sigma**2`) term which, when fitted, predicts unrealistically high voice jitter. This is because it has picked up all kinds of other effects in the data, working as a 'shock absorber' to keep the other GP parameters unharmed. We acknowledge this and during inference of the latent GP function replace this $\\sigma_n^2$ noise term by zero. We still have inherent jitter in the process which we calculate below. It is likely that the jitter has been learned to some degree by the kernel because the `Matern32Kernel` is preferred over `Matern52Kernel` and `SqExponentialKernel`.\n",
    "\n",
    "Note: we could circumvent this by using a Student-T process instead of a GP, which would absorp these shocks (i.e., outliers) for us, resulting in a more realistic $\\sigma_n^2$ value which would relative more directly to jitter.\n",
    "\n",
    "## Can we use `TIMIT-voiced`?\n",
    "\n",
    "No.\n",
    "\n",
    "The TIMIT-voiced database does not have GCI information; the frames nearly constant-length and give only voiced/unvoiced information.\n",
    "In addition, I could not find a reference, and I think these values have been auto-generated and not manually verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run init.ipy\n",
    "\n",
    "from lib import aplawd\n",
    "from lib import praat\n",
    "from dgf import bijectors\n",
    "from dgf import isokernels\n",
    "from dgf import core\n",
    "from dgf import constants\n",
    "from dgf.prior import period\n",
    "\n",
    "import dynesty\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import itertools\n",
    "import scipy.stats\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot samples from APLAWD\n",
    "\n",
    "The distribution of the unconstrained (i.e., transformed) $z = b^{-1}(T)$ variable is bimodal, pointing to the sex of the speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = aplawd.APLAWD(__datadir__('APLAWDW/dataset'))\n",
    "markings = aplawd.APLAWD_Markings(__datadir__('APLAWDW/markings/aplawd_gci'))\n",
    "\n",
    "def plot_recording_and_degg(recordings, markings, key):\n",
    "    \"\"\"Adapted from https://github.com/serwy/aplawdw/blob/master/demo_001.py\"\"\"\n",
    "    aplawd_db = recordings\n",
    "    markings_db = markings\n",
    "\n",
    "    key = np.random.choice(aplawd_db.keys())\n",
    "\n",
    "    recording = aplawd_db.load_shifted(key)\n",
    "    recording_gci = markings_db.load(recording.name)\n",
    "\n",
    "    ax = plt.subplot(211)\n",
    "    t = np.arange(len(recording.s)) / recording.fs\n",
    "    plt.plot(t, recording.s, alpha=0.5)\n",
    "    plt.ylabel('speech')\n",
    "    plt.title('APLAWD waveform: %s' % recording.name)\n",
    "\n",
    "    plt.subplot(212, sharex=ax)\n",
    "    t = np.arange(len(recording.d)) / recording.fs\n",
    "\n",
    "    plt.plot(t, recording.d, alpha=0.5, label='DEGG')\n",
    "\n",
    "    plt.plot(t[recording_gci], 0*recording_gci, 'o', ms=5, alpha=0.5,\n",
    "             label='reference markings')\n",
    "\n",
    "    plt.legend(loc='lower right', fancybox=True, framealpha=0.5)\n",
    "    plt.ylabel('DEGG')\n",
    "    plt.xlabel('time (s)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_recording_and_degg(recordings, markings, recordings.random_key())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustrate the data gathering process: `period.yield_training_pairs()`\n",
    "\n",
    "We pair the manually checked markings with Praat's pulse estimates.\n",
    "Each recording is split into groups of voiced markings and those groups are matched and aligned with Praat's pulse estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = recordings.random_key()\n",
    "\n",
    "k, m = period.load_recording_and_markers(recordings, markings, key)\n",
    "pulses = praat.get_pulses(k.s, k.fs)\n",
    "f = 1000/k.fs\n",
    "\n",
    "title(f'Full waveform: {key}')\n",
    "plot(k.s)\n",
    "for p in m: axvline(p, color='black')\n",
    "for p in pulses: axvline(p, color='pink')\n",
    "#xlim(1800, 2300)\n",
    "show()\n",
    "\n",
    "figure()\n",
    "title('Diff of GCI markers')\n",
    "plot(diff(m)*f)\n",
    "plot(diff(pulses)*f)\n",
    "ylabel('msec')\n",
    "xlabel('index')\n",
    "show()\n",
    "\n",
    "MIN_NUM_PERIODS = 3\n",
    "\n",
    "voiced_groups = period.split_markings_into_voiced_groups(\n",
    "    m, k.fs, constants.MAX_PERIOD_LENGTH_MSEC, MIN_NUM_PERIODS\n",
    ")\n",
    "\n",
    "for group in voiced_groups:\n",
    "    if len(group) <= MIN_NUM_PERIODS + 1: continue\n",
    "\n",
    "    group_periods = np.diff(group)*f # msec\n",
    "    display(group_periods)\n",
    "    \n",
    "    group, group_praat = period.align_and_intersect(group, pulses)\n",
    "    assert len(group) == len(group_praat)\n",
    "    if len(group) <= MIN_NUM_PERIODS + 1:\n",
    "        continue\n",
    "\n",
    "    praat_periods = np.diff(group_praat) / k.fs * 1000 # msec\n",
    "    if np.any(praat_periods > constants.MAX_PERIOD_LENGTH_MSEC):\n",
    "        # Discard this and continue; we assume user will never accept\n",
    "        # such Praat estimates so we don't want to model this case.\n",
    "        warnings.warn(\n",
    "            f'Discarded voiced group of GCIs because one of the synced '\n",
    "            f'Praat periods is longer than {constants.MAX_PERIOD_LENGTH_MSEC} msec'\n",
    "        )\n",
    "        continue\n",
    "    \n",
    "    figure()\n",
    "    title('Waveform of local voiced group with GCI estimates')\n",
    "    t = np.arange(group[0], group[-1])\n",
    "    plot(t*f, k.s[group[0] : group[-1]])\n",
    "    for p in group: axvline(p*f, color='black')\n",
    "    for p in group_praat: axvline(p*f, color='pink')\n",
    "    xlabel('time [msec]')\n",
    "    \n",
    "    show()\n",
    "    \n",
    "    figure()\n",
    "    title('Pitch period length trajectory')\n",
    "    plot(np.diff(group) * f)\n",
    "    plot(np.diff(group_praat) * f)\n",
    "    xlabel('pitch period index')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot marginal statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pairs, training_pairs_z = period.get_aplawd_training_pairs()\n",
    "\n",
    "# Check if everything is within the bijector bounds\n",
    "assert not np.any(np.concatenate([np.isnan(x) | np.isnan(y) for x, y in training_pairs_z]))\n",
    "\n",
    "def plot_marginal(training_pairs, lab):\n",
    "    true_marginal = []\n",
    "    praat_marginal = []\n",
    "\n",
    "    for true_group, praat_group in training_pairs:\n",
    "        true_marginal.append(true_group)\n",
    "        praat_marginal.append(praat_group)\n",
    "\n",
    "    true_marginal = np.concatenate(true_marginal)\n",
    "    praat_marginal = np.concatenate(praat_marginal)\n",
    "\n",
    "    hist([true_marginal, praat_marginal], bins=50)\n",
    "    xlabel(lab)\n",
    "    \n",
    "    return true_marginal, praat_marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data_points = np.array([len(pair[0]) for pair in training_pairs])\n",
    "hist(len_data_points, bins=50)\n",
    "pd.DataFrame(len_data_points).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_marginal, praat_marginal = plot_marginal(training_pairs, 'Pitch period [msec]')\n",
    "pd.DataFrame({'true': true_marginal, 'Praat': praat_marginal}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_marginal_z, praat_marginal_z = plot_marginal(training_pairs_z, 'z')\n",
    "pd.DataFrame({'true': true_marginal_z, 'Praat': praat_marginal_z}).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit GP model\n",
    "\n",
    "The GP model for the true GCI markings is independent of the Praat observation model, so we train them separately.\n",
    "\n",
    "The observation noise $\\sigma_n^2$ (`noise_sigma**2`) relates to voice jitter.\n",
    "\n",
    "The `Matern32Kernel` has the highest posterior probability. The fitted source envelope lengthscales $\\lambda$ differ quite strongly between the kernels, with highest evidence for $\\lambda \\approx 10$.\n",
    "\n",
    "The `Matern12Kernel` did converge but has a very long lengthscale, but low evidence. **So there is a preference for some roughness, but not too much: this indicates the learning of a jitter component.**\n",
    "\n",
    "The Praat observation error is fitted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nested sampling inference for these kernels takes around 5 +/- 0.5 hrs\n",
    "for kernel_name in ('Matern12Kernel', 'Matern32Kernel', 'Matern52Kernel', 'SqExponentialKernel'):\n",
    "    results = period.model_true_pitch_periods(kernel_name, 32)\n",
    "    print(kernel_name)\n",
    "    print(results.summary())\n",
    "    print('Information (bans):', results.information[-1] * log10(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynesty import plotting\n",
    "\n",
    "def plot_kernel_results(kernel_name, kernel_M = 32):\n",
    "    results = period.model_true_pitch_periods(kernel_name, kernel_M)\n",
    "\n",
    "    display(kernel_name)\n",
    "    display(results.summary())\n",
    "    display('Information (bans)', results.information[-1] * log10(e))\n",
    "    \n",
    "    VARIABLE_NAMES = ['mean', 'sigma', 'scale', 'noise_sigma']\n",
    "    fig, axes = dynesty.plotting.traceplot(\n",
    "        results, show_titles=True,\n",
    "        labels=VARIABLE_NAMES,\n",
    "        verbose=True\n",
    "    )\n",
    "    tight_layout()\n",
    "\n",
    "    fg, ax = dynesty.plotting.cornerplot(results, labels=VARIABLE_NAMES)\n",
    "    tight_layout()\n",
    "    show()\n",
    "\n",
    "plot_kernel_results('Matern12Kernel')\n",
    "plot_kernel_results('Matern32Kernel')\n",
    "plot_kernel_results('Matern52Kernel')\n",
    "plot_kernel_results('SqExponentialKernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Praat observation error\n",
    "\n",
    "We model `p(T_praat | T_true) = N(T_true, praat_sigma² * I)`. `praat_sigma` is 0.05 or about half of `noise_sigma` above, so quite substantial correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 30 minutes\n",
    "results = period.model_praat_pitch_periods()\n",
    "\n",
    "display(results.summary())\n",
    "display('Information (bans)', results.information[-1] * log10(e))\n",
    "\n",
    "VARIABLE_NAMES = ['praat_sigma']\n",
    "fig, axes = dynesty.plotting.traceplot(\n",
    "    results, show_titles=True,\n",
    "    labels=VARIABLE_NAMES,\n",
    "    verbose=True\n",
    ")\n",
    "tight_layout()\n",
    "\n",
    "fg, ax = dynesty.plotting.cornerplot(results, labels=VARIABLE_NAMES)\n",
    "tight_layout()\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period.fit_aplawd_z()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_prior = period.marginal_prior()\n",
    "\n",
    "samples = period_prior.sample(int(1e5), seed=jax.random.PRNGKey(50))\n",
    "\n",
    "hist(1000/true_marginal, bins=50, alpha=.5, density=True, label='APLAWD');\n",
    "hist(1000/np.asarray(samples), bins=50, alpha=.5, density=True, label='Fitted model');\n",
    "legend()\n",
    "xlabel('Fundamental frequency F0 (Hz)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 30\n",
    "\n",
    "prior = period.trajectory_prior(P)\n",
    "samples = prior.sample(5, seed=jax.random.PRNGKey(randint(0,1000)))\n",
    "plot(samples.T)\n",
    "xlabel('Pitch period index');\n",
    "ylabel('Period [msec]');\n",
    "title('Period trajectory prior');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praat_estimate = [7.]*40\n",
    "\n",
    "prior = period.trajectory_prior(praat_estimate=praat_estimate)\n",
    "samples = prior.sample(1, seed=jax.random.PRNGKey(randint(0,1000)))\n",
    "plot(praat_estimate, '--', label=\"given Praat estimate\")\n",
    "plot(samples.T, label=\"conditioned trajectory\")\n",
    "legend()\n",
    "xlabel('Pitch period index');\n",
    "ylabel('Period [msec]');\n",
    "title('Period trajectory prior given Praat estimate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure jitter\n",
    "\n",
    "The jitter implied by the prior is reasonably realistic. We use Praat's `jitter (local, absolute)` from <https://www.fon.hum.uva.nl/praat/manual/Voice_2__Jitter.html> because it is less sensitive to what we choose as a consistent group of pitch periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_JITTER_USEC = 1000\n",
    "NUM_SAMPLES = int(1e4)\n",
    "NUMBINS = 50\n",
    "\n",
    "# Measure APLAWD jitter over voiced groups\n",
    "def measure_jitter(x):\n",
    "    # https://www.fon.hum.uva.nl/praat/manual/PointProcess__Get_jitter__local__absolute____.html\n",
    "    return float(np.mean(np.abs(np.diff(x))))\n",
    "\n",
    "aplawd_jitter = np.array([measure_jitter(true_period) for (true_period, _) in training_pairs])\n",
    "aplawd_jitter_usec = aplawd_jitter*1000\n",
    "aplawd_jitter_usec = aplawd_jitter_usec[aplawd_jitter_usec < MAX_JITTER_USEC]\n",
    "\n",
    "# Measure jitter from GP prior over one lengthscale\n",
    "fit_z = period.fit_aplawd_z()\n",
    "P = int(fit_z['scale']) # Measure over one lengthscale (has little influence)\n",
    "\n",
    "prior = period.trajectory_prior(P)\n",
    "samples = prior.sample(NUM_SAMPLES, seed=jax.random.PRNGKey(48702))\n",
    "\n",
    "prior_jitter = np.mean(np.abs(np.diff(samples,axis=1)),axis=1)\n",
    "prior_jitter_usec = prior_jitter*1000\n",
    "prior_jitter_usec = prior_jitter_usec[prior_jitter_usec < MAX_JITTER_USEC]\n",
    "\n",
    "# Plot\n",
    "hist(aplawd_jitter_usec, bins=NUMBINS, alpha=0.5, density=True, label='APLAWD');\n",
    "hist(prior_jitter_usec, bins=NUMBINS, alpha=0.5, density=True, label='prior');\n",
    "axvline(83.200, label='Pathology treshold')\n",
    "legend()\n",
    "title('Measured jitter from APLAWD vs prior')\n",
    "xlabel('Local absolute jitter (microseconds)');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
